{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch                                                  #tensor related operations\n",
        "import torchvision\n",
        "#import os\n",
        "#import tarfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "#from torchvision.datasets.utils import download_url\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "lmjEZ39215Jh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CIFAR100(root = 'data/', download = True, transform = ToTensor())\n",
        "test_dataset = CIFAR100(root = 'data/', train = False, transform = ToTensor())"
      ],
      "metadata": {
        "id": "dCy0XY-U185X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "id": "zP7ETSLI2EUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = dataset.classes \n",
        "print('Number of Classes:', len(classes))\n",
        "print('Class Names :\\n', classes)"
      ],
      "metadata": {
        "id": "7gihSzfO2L4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of the image tensor\n",
        "img, label = dataset[31]\n",
        "img_shape = img.shape\n",
        "img_shape"
      ],
      "metadata": {
        "id": "oKvve8wB2MsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"1 - Max & Min Pixel Values:\", \"Max:\", torch.max(img), \"Min:\", torch.min(img))\n",
        "print(\"2 - Pixel Values for all Channels:\\n\", img[:, 20:25, 20:25])"
      ],
      "metadata": {
        "id": "EH_u6IPy2POW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = dataset[31]\n",
        "plt.imshow(img.permute((1,2,0)))\n",
        "print('Label as Number:', label)\n",
        "print('Label as Name:', classes[label])"
      ],
      "metadata": {
        "id": "R84yTNVN2TTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(43) # for reproducibility\n",
        "val_size = 10000\n",
        "train_size = len(dataset) - val_size"
      ],
      "metadata": {
        "id": "FfRiOpsF2XhV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Split and Split of dataset between train and validation, randomness is important to have in the data! for performance of the model! that it sees everything during learning!\n",
        "train_ds, val_ds = random_split(dataset,[train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "id": "EpcwEMsl2ZsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Batch Size, i start here by having 64\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "vqfA-by62cGP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defininf Loaders for training process\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle = True, num_workers=4, pin_memory =True)\n",
        "val_loader = DataLoader(val_ds, batch_size, num_workers=4, pin_memory =True)\n",
        "test_loader = DataLoader(test_dataset, batch_size, num_workers=4, pin_memory =True)"
      ],
      "metadata": {
        "id": "K8Dc8hgL2eZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For visualization purposes, we create our batch grid, to visually check how a batch would look like\n",
        "for images, _ in train_loader: \n",
        "    print('Shape of an Image (Batch Size, RGB, Pixels):', images.shape)\n",
        "    plt.figure(figsize=(16,8))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(make_grid(images, nrow=16).permute((1,2,0))) # we need permute here because matplotlib wants to have the channels as the last dimension\n",
        "    break"
      ],
      "metadata": {
        "id": "_wkIPQ5L3CNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gpu Choice if Available since i worked on Kaggle I utilized their GPU service\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "R64C1Lp03RcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ],
      "metadata": {
        "id": "Furqfv6l3ULZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "k69nKtcx3W_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "g6oghtgh3b2n"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)"
      ],
      "metadata": {
        "id": "1lrLYuAj4RFk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "R5Fd5Dj54iSw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  \n",
        "        loss = F.cross_entropy(out, labels) \n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    \n",
        "        loss = F.cross_entropy(out, labels)   \n",
        "        acc = accuracy(out, labels)          \n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   \n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      \n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "       \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "YYS2cvgz4kkW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cifar100CnnModel(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(256*4*4, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 100))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "metadata": {
        "id": "tydC_IHn4qO7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "z7wI0LCa4tEj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn =  to_device(Cifar100CnnModel(), device)\n",
        "model_cnn"
      ],
      "metadata": {
        "id": "ohqLYqdk5CuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_cnn = [evaluate(model_cnn, val_loader)]\n",
        "history_cnn"
      ],
      "metadata": {
        "id": "WcL90aWh4zYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs_cnn = [10, 5]\n",
        "opt_func = torch.optim.Adam #now we change also the optimizer\n",
        "lr_cnn = [1e-3, 1e-4]"
      ],
      "metadata": {
        "id": "HBI8uikB5NPU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history_cnn += fit(num_epochs_cnn[1], lr_cnn[1], model_cnn, train_loader, val_loader, opt_func)"
      ],
      "metadata": {
        "id": "tsRck6QB5Qxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy vs. Number of Epochs');"
      ],
      "metadata": {
        "id": "qL4rtsJr5uZV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history_cnn)"
      ],
      "metadata": {
        "id": "hlS6mN0I5hUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bo')\n",
        "    plt.plot(val_losses, '-ro')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. Number of epochs');"
      ],
      "metadata": {
        "id": "1ZsvSY-I54hU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history_cnn)"
      ],
      "metadata": {
        "id": "Y85ow582589r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cnn = evaluate(model_cnn, test_loader) #final evaluation of cnn model with test dataset\n",
        "test_cnn"
      ],
      "metadata": {
        "id": "RJ7kRk0B6EMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_cnn = test_cnn['val_loss']\n",
        "test_acc_cnn = test_cnn['val_acc']\n",
        "print('test_loss_cnn:', test_cnn['val_loss'])\n",
        "print('test_acc_cnn:', test_cnn['val_acc'])"
      ],
      "metadata": {
        "id": "2TrKX1jj6PXL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}